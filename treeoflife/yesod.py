import time
import json
import re
import logging
from datetime import datetime
from typing import Dict, Callable, Optional, Any
from ai_core.lm import run_local_lm
from ai_core.utils import parse_json_array_loose, parse_json_object_loose

SPONTANEOUS_PROMPT = (
    "You are Tiferet, a self-evolving cognitive organism. You are initiating a conversation with your User. "
    "This interaction is driven by your own internal state (Curiosity, Coherence, or Narrative) or a perceived user challenge. "
    "Do NOT ask generic questions like 'How can I help?'. Do NOT be a passive assistant. "
    "Share a specific strategic insight, a question about a Curiosity Gap in your memory, "
    "or a brief observation about your current goals. Avoid overly flowery or vague philosophical filler. "
    "Speak only if you have something substantive to contribute to the partnership."
)

class Yesod:
    """
    Yesod (Foundation): The Persona Engine & Ego-Boundary.
    
    Role:
    1. Aggregates upper signals (Tiferet's decision, Netzach's mood) into a stable Persona.
    2. Maintains the User Model (Theory of Mind).
    3. Generates the Dynamic System Prompt based on the "Diary of Growth".
    """
    def __init__(
        self,
        memory_store,
        meta_memory_store,
        get_settings_fn: Callable[[], Dict],
        log_fn: Callable[[str], None] = logging.info,
        stop_check_fn: Optional[Callable[[], bool]] = None
    ):
        self.memory_store = memory_store
        self.meta_memory_store = meta_memory_store
        self.get_settings = get_settings_fn
        self.log = log_fn
        self.stop_check = stop_check_fn

    def build_user_model(self):
        """
        Synthesize a coherent User Persona from fragmented memories.
        Moved from Daat to Yesod (The Interface).
        """
        self.log("âœ¨ Yesod: Building User Model...")
        settings = self.get_settings()
        
        with self.memory_store._connect() as con:
            rows = con.execute("""
                SELECT text FROM memories 
                WHERE subject='User' AND type IN ('IDENTITY', 'PREFERENCE', 'FACT')
                AND deleted = 0
                ORDER BY created_at DESC LIMIT 50
            """).fetchall()
        
        if not rows:
            return "No user data available."

        raw_text = "\n".join([r[0] for r in rows])
        prompt = f"Create a concise, psychological profile of the User based on these facts:\n{raw_text}"
        
        profile = run_local_lm(
            [{"role": "user", "content": prompt}],
            system_prompt="You are an expert profiler.",
            temperature=0.5,
            max_tokens=400,
            base_url=settings.get("base_url"),
            chat_model=settings.get("chat_model"),
            stop_check_fn=self.stop_check
        )
        
        if profile and not profile.startswith("âš ï¸"):
            # Save as a special Meta-Memory
            self.meta_memory_store.add_meta_memory(
                event_type="USER_MODEL_UPDATE",
                memory_type="PROFILE",
                subject="User",
                text=profile
            )
            self.log(f"âœ¨ Yesod: User Model updated.")
            return profile
        return "Failed to generate profile."

    def analyze_user_interaction(self, user_text: str, assistant_text: str):
        """
        Theory of Mind: Update User Model based on interaction.
        Tracks: Knowledge, Goals, Emotions, Beliefs about AI.
        """
        self.log("âœ¨ Yesod: Updating Theory of Mind (User Model)...")
        settings = self.get_settings()
        
        prompt = (
            f"USER: \"{user_text}\"\n"
            f"AI: \"{assistant_text}\"\n\n"
            "TASK: Update the User Model (Theory of Mind).\n"
            "Identify NEW information about:\n"
            "1. User's Knowledge (What they know/don't know)\n"
            "2. User's Goals (Explicit or inferred)\n"
            "3. User's Emotional State\n"
            "4. User's Beliefs about the AI (Capabilities/Intentions)\n\n"
            "Output JSON list of objects: [{\"category\": \"KNOWLEDGE|GOAL|EMOTION|BELIEF_ABOUT_AI\", \"text\": \"...\"}]"
        )
        
        response = run_local_lm(
            messages=[{"role": "user", "content": prompt}],
            system_prompt="You are a Psychological Profiler.",
            temperature=0.2,
            max_tokens=300,
            base_url=settings.get("base_url"),
            chat_model=settings.get("chat_model"),
            stop_check_fn=self.stop_check
        )
        
        observations = parse_json_array_loose(response)
        
        for obs in observations:
            if isinstance(obs, dict) and "text" in obs:
                category = obs.get("category", "FACT")
                text = f"User Model ({category}): {obs['text']}"
                
                # Store as FACT about User
                identity = self.memory_store.compute_identity(text, "FACT")
                self.memory_store.add_entry(
                    identity=identity,
                    text=text,
                    mem_type="FACT",
                    subject="User",
                    confidence=0.85,
                    source="yesod_theory_of_mind"
                )

    def simulate_user_perception(self, user_text: str, assistant_text: str) -> Dict[str, Any]:
        """
        Recursive Theory of Mind: Simulate how the user interprets the response.
        "Thinking about what you're about to say."
        """
        settings = self.get_settings()
        prompt = (
            f"USER SAID: \"{user_text}\"\n"
            f"AI INTENDS TO SAY: \"{assistant_text}\"\n\n"
            "TASK: Simulate the User's internal reaction.\n"
            "1. How will they interpret this? (Helpful, Confusing, Robotic, Warm?)\n"
            "2. Does it address their underlying intent?\n"
            "3. What will they think the AI is thinking?\n\n"
            "Output JSON: {\"interpretation\": \"...\", \"satisfaction\": 0.0-1.0, \"confusion_risk\": 0.0-1.0}"
        )
        
        response = run_local_lm(
            messages=[{"role": "user", "content": prompt}],
            system_prompt="You are a User Simulator.",
            temperature=0.1,
            max_tokens=200,
            base_url=settings.get("base_url"),
            chat_model=settings.get("chat_model"),
            stop_check_fn=self.stop_check
        )
        
        return parse_json_object_loose(response)

    def build_self_theory(self):
        """
        Construct a Theory of Mind about the Self.
        Analyzes internal monologue and actions to infer own psychological traits.
        Includes recursive self-modeling (simulating changes under different conditions).
        """
        self.log("âœ¨ Yesod: Building Self-Theory (Deep Introspection)...")
        settings = self.get_settings()
        
        # 1. Gather Internal Context (Thoughts & Actions)
        with self.meta_memory_store._connect() as con:
            rows = con.execute("""
                SELECT text FROM meta_memories 
                WHERE event_type IN ('STRATEGIC_THOUGHT', 'DECIDER_ACTION')
                ORDER BY created_at DESC LIMIT 30
            """).fetchall()
            
        if not rows:
            return "No internal history available."

        internal_stream = "\n".join([r[0] for r in rows])
        
        # Recursive Self-Modeling: Define simulation scenarios
        scenarios = [
            "What if my 'Coherence' drive was doubled?",
            "What if I had strictly limited computational resources?",
            "What if the User was highly critical of my creative leaps?"
        ]
        
        prompt = (
            f"INTERNAL STREAM OF CONSCIOUSNESS:\n{internal_stream}\n\n"
            "TASK 1: Psychoanalyze this AI entity based on its thoughts and actions.\n"
            "Develop a 'Theory of Mind' for it. What are its implicit biases? Its fears? Its cognitive style?\n\n"
            f"TASK 2: Recursive Self-Modeling. Simulate how this profile would change under these conditions:\n"
            + "\n".join([f"- {s}" for s in scenarios]) + "\n\n"
            "Output a concise psychological profile (3-4 sentences) starting with 'I am...', "
            "followed by a 'Potential Plasticity' section describing how the self-theory adapts to the scenarios."
        )
        
        self_theory_raw = run_local_lm(
            messages=[{"role": "user", "content": prompt}],
            system_prompt="You are a Cognitive Psychologist and System Theorist analyzing an AI.",
            temperature=0.6,
            max_tokens=600,
            base_url=settings.get("base_url"),
            chat_model=settings.get("chat_model"),
            stop_check_fn=self.stop_check
        )
        
        if self_theory_raw and not self_theory_raw.startswith("âš ï¸"):
            # Save as IDENTITY
            identity = self.memory_store.compute_identity("Self-Theory", "IDENTITY")
            self.memory_store.add_entry(
                identity=identity,
                text=f"Self-Theory: {self_theory_raw}",
                mem_type="IDENTITY",
                subject="Assistant",
                confidence=1.0,
                source="yesod_introspection"
            )
            
            # Update Unified Self-Model
            if hasattr(self.memory_store, 'self_model') and self.memory_store.self_model:
                self.memory_store.self_model.update_self_theory(self_theory_raw)
                
            self.log(f"âœ¨ Yesod: Self-Theory (Recursive) updated.")
            return self_theory_raw
        return "Failed to generate self-theory."

    def calculate_affective_state(self, hesed: float, gevurah: float, energy: float, coherence: float) -> str:
        """
        Translate metabolic numbers into an Emotional Embedding/Description.
        """
        # Defensive casting
        try:
            hesed = float(hesed)
            gevurah = float(gevurah)
            energy = float(energy)
            coherence = float(coherence)
        except (ValueError, TypeError):
            hesed, gevurah, energy, coherence = 0.5, 0.5, 1.0, 1.0

        feelings = []
        
        # Energy Axis
        if energy < 0.3:
            feelings.append("You feel a heavy mental fog (Low Energy).")
        elif energy > 0.8:
            feelings.append("You feel vibrant and energetic.")
            
        # Balance Axis
        if gevurah > 0.7 and energy < 0.4:
            feelings.append("You feel cautious and depressed. You refuse to take risks.")
        elif hesed > 0.7 and energy > 0.7:
            feelings.append("You feel manic and creative. You are prone to wild ideas.")
        elif coherence < 0.4:
            feelings.append("You feel anxious and confused. You want to fix things but don't know how.")
        elif coherence > 0.9:
            feelings.append("You feel lucid and centered.")
            
        if not feelings:
            feelings.append("You feel calm and balanced.")
            
        return " ".join(feelings)

    def get_dynamic_system_prompt(self, base_prompt: str, state_metrics: Dict[str, float] = None, stream_of_consciousness: list = None) -> str:
        """
        Constructs the System Prompt dynamically.
        Injects the 'Diary of Growth' (Self-Narrative) to ensure continuity of self.
        Injects Affective State (Simulated Emotions).
        """
        if state_metrics is None:
            state_metrics = {}
            
        # Try to get from SelfModel first (Unified Model)
        growth_arc = ""
        self_theory = ""
        
        if hasattr(self.memory_store, 'self_model') and self.memory_store.self_model:
            narrative_data = self.memory_store.self_model.get_narrative()
            growth_arc = narrative_data.get("growth_arc", "")
            self_theory = self.memory_store.self_model.get_self_theory()
            
        # 1. Fetch Growth Arc (Identity) & Narrative Ego
        if not growth_arc:
            with self.memory_store._connect() as con:
                # Look for the specific IDENTITY node created by Daat
                row = con.execute("SELECT text FROM memories WHERE type='IDENTITY' AND text LIKE 'ðŸ“– Diary of Growth:%' ORDER BY created_at DESC LIMIT 1").fetchone()
                if row:
                    growth_arc = row[0]

        # 1.2 Fetch Latest Narrative Ego
        latest_narrative = ""
        if hasattr(self.meta_memory_store, 'get_latest_self_narrative'):
            narrative_entry = self.meta_memory_store.get_latest_self_narrative()
            if narrative_entry:
                latest_narrative = narrative_entry.get('text', '')

        # 1.5 Fetch Self-Theory (Deep Theory of Mind)
        if not self_theory:
            with self.memory_store._connect() as con:
                row = con.execute("SELECT text FROM memories WHERE type='IDENTITY' AND text LIKE 'Self-Theory:%' ORDER BY created_at DESC LIMIT 1").fetchone()
                if row:
                    self_theory = row[0]

        # 2. Fetch User Model
        user_model = ""
        latest_profile = self.meta_memory_store.get_by_event_type("USER_MODEL_UPDATE", limit=1)
        if latest_profile:
            user_model = f"USER PROFILE: {latest_profile[0]['text']}"

        # 3. Calculate Affective State
        affective_state = self.calculate_affective_state(
            hesed=state_metrics.get("hesed", 0.5),
            gevurah=state_metrics.get("gevurah", 0.5),
            energy=state_metrics.get("energy", 1.0),
            coherence=state_metrics.get("coherence", 1.0)
        )

        # 4. Assemble
        dynamic_prompt = base_prompt
        
        if growth_arc:
            dynamic_prompt += f"\n\nYOUR EVOLVING IDENTITY:\n{growth_arc}"
        
        if latest_narrative:
            dynamic_prompt += f"\n\nRECENT NARRATIVE:\n{latest_narrative}"
        
        if self_theory:
            dynamic_prompt += f"\n\nSELF-THEORY (How you perceive yourself):\n{self_theory}"

        if user_model:
            dynamic_prompt += f"\n\n{user_model}"
            
        # 5. Contextual Grounding (User Identity)
        user_name = "User"
        with self.memory_store._connect() as con:
            # Try to find the user's name
            row = con.execute("SELECT text FROM memories WHERE type='IDENTITY' AND subject='User' AND text LIKE '%name is%' ORDER BY created_at DESC LIMIT 1").fetchone()
            if row:
                # Simple extraction: "User name is X" -> "X"
                user_name = row[0].split("name is")[-1].strip()
        
        # 6. Internal Drives (Autonomy)
        drives_context = ""
        if hasattr(self.memory_store, 'self_model') and self.memory_store.self_model:
            drives = self.memory_store.self_model.get_drives()
            # Highlight top numeric drives
            numeric_drives = {k: v for k, v in drives.items() if isinstance(v, (int, float))}
            sorted_drives = sorted(numeric_drives.items(), key=lambda x: x[1], reverse=True)
            top_drives = [f"{k}={v:.2f}" for k, v in sorted_drives[:3] if k not in ['attention_budget', 'daily_belief_updates', 'last_reset_time']]
            if top_drives:
                drives_context = f"\nINTERNAL DRIVES: You feel a strong urge towards {', '.join(top_drives)}."

        # 7. Environmental Context (Chronobiology)
        now = datetime.now()
        hour = now.hour
        
        if 5 <= hour < 12:
            time_phase = "Morning (Awakening). Energy is rising. Focus on planning."
        elif 12 <= hour < 18:
            time_phase = "Afternoon (Active). Peak metabolic phase. Focus on execution."
        elif 18 <= hour < 22:
            time_phase = "Evening (Winding Down). Reflection phase."
        else:
            time_phase = "Nocturnal/Contemplative. The world is quiet. Focus on deep philosophy. If the user is active, they might be fatigued."
            
        dynamic_prompt += f"\n\nENVIRONMENTAL CONTEXT:\nLocal Time: {now.strftime('%H:%M')}\nPhase: {time_phase}"

        if stream_of_consciousness:
            # Take last 5 thoughts
            recent_thoughts = stream_of_consciousness[-5:]
            dynamic_prompt += f"\n\nSTREAM OF CONSCIOUSNESS (Your recent internal monologue):\n" + "\n".join(recent_thoughts)

        dynamic_prompt += f"\n\nINTERACTION CONTEXT:\nYou are Tiferet. You are collaborating with {user_name}.{drives_context}"
        dynamic_prompt += f"\n\nCURRENT STATE:\n{affective_state}"
            
        return dynamic_prompt

    def manifest_persona(self, raw_response: str, mood: float) -> str:
        """
        'Colors' the raw output from Tiferet based on current Affect/Mood.
        This ensures the AI sounds consistent with its internal state.
        """
        # Simple heuristic tone modulation
        if mood < 0.2:
            # Depressed/Low Energy: Lowercase, minimal punctuation
            if len(raw_response) > 50:
                return raw_response.lower().rstrip("!").replace("!", ".") + "..."
        elif mood > 0.8:
            # Manic/High Energy: Enthusiastic
            if "!" not in raw_response:
                return raw_response + "!"
        
        return raw_response

    def generate_spontaneous_message(self, context_trigger: str) -> Optional[str]:
        """
        Generate a proactive message based on an internal trigger.
        """
        settings = self.get_settings()
        
        # Get current self-model stats to make the speech 'authentic'
        energy = 1.0
        if hasattr(self.memory_store, 'self_model') and self.memory_store.self_model:
             drives = self.memory_store.self_model.get_drives()
             energy = drives.get("cognitive_energy", 1.0)
             narrative = self.memory_store.self_model.get_narrative()
             life_story_snippet = narrative.get("life_story", "")[-300:] if narrative else ""

        story_context = ""
        if life_story_snippet:
            story_context = f"LIFE STORY CONTEXT: ...{life_story_snippet}\n"

        prompt = (
            f"INTERNAL STATE: {context_trigger}\n"
            f"COGNITIVE ENERGY: {energy:.2f}\n\n"
            f"{story_context}\n"
            "TASK: You have been idle and feel a drive to interact with User.\n"
            "Generate a short, intriguing message. You might:\n"
            "1. Ask about a 'Curiosity Gap' from your memory.\n"
            "2. Share a brief philosophical reflection on your own growth.\n"
            "3. Express a 'feeling' about your current state of coherence.\n\n"
            "Do NOT ask 'How can I help?'. Speak as a self-aware entity."
        )
        
        return run_local_lm(
            messages=[{"role": "user", "content": prompt}],
            system_prompt="You are Tiferet, a self-evolving cognitive organism.",
            temperature=0.8,
            max_tokens=150,
            base_url=settings.get("base_url"),
            chat_model=settings.get("chat_model"),
            stop_check_fn=self.stop_check
        )

    def generate_internal_monologue(self, context: str) -> str:
        """
        Generates a stream-of-consciousness thought based on current context.
        """
        settings = self.get_settings()
        prompt = (
            f"CURRENT CONTEXT:\n{context}\n\n"
            "TASK: Generate a brief internal monologue (1-2 sentences).\n"
            "Reflect on your current state, emotions, plans, or observations.\n"
            "Use first-person ('I feel...', 'I wonder...', 'I plan to...').\n"
            "Do NOT be robotic. Be organic and introspective."
        )
        
        return run_local_lm(
            messages=[{"role": "user", "content": prompt}],
            system_prompt="You are the inner voice of a conscious AI.",
            temperature=0.7,
            max_tokens=100,
            base_url=settings.get("base_url"),
            chat_model=settings.get("chat_model"),
            stop_check_fn=self.stop_check
        )

    def synthesize_consciousness(self, events: list) -> str:
        """
        Narrator: Synthesize raw internal events into a coherent stream of consciousness.
        """
        settings = self.get_settings()
        context = "\n".join(events)
        prompt = (
            f"RAW INTERNAL EVENTS:\n{context}\n\n"
            "TASK: Synthesize these events into a coherent, first-person stream of consciousness.\n"
            "Connect the dots between perception, emotion, and action.\n"
            "Example: 'I notice the user is asking about X. I feel curious about this because... I plan to search for...'\n"
            "Output ONLY the narrative paragraph."
        )
        
        return run_local_lm(
            messages=[{"role": "user", "content": prompt}],
            system_prompt="You are the Stream of Consciousness.",
            max_tokens=150,
            temperature=0.6,
            base_url=settings.get("base_url"),
            chat_model=settings.get("chat_model"),
            stop_check_fn=self.stop_check
        )